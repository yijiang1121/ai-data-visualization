<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Grading Accuracy Dashboard</title>
    <style>
      :root {
        color-scheme: light dark;
        --bg: #f5f5f9;
        --card-bg: #ffffffcc;
        --card-shadow: rgba(15, 23, 42, 0.12);
        --text-primary: #0f172a;
        --text-secondary: #475569;
        --accent: #2563eb;
        --accent-soft: rgba(37, 99, 235, 0.12);
        --success: #059669;
        --warning: #d97706;
      }

      * {
        box-sizing: border-box;
      }

      body {
        margin: 0;
        font-family: "Inter", "Segoe UI", -apple-system, BlinkMacSystemFont, sans-serif;
        background: linear-gradient(160deg, var(--bg) 0%, #e2e8f0 100%);
        color: var(--text-primary);
        min-height: 100vh;
        display: flex;
        flex-direction: column;
      }

      header {
        padding: 3rem 1.5rem 2rem;
        text-align: center;
      }

      header h1 {
        margin: 0 0 0.5rem;
        font-size: clamp(2rem, 5vw, 2.8rem);
        letter-spacing: -0.02em;
      }

      header p {
        margin: 0 auto;
        max-width: 48rem;
        color: var(--text-secondary);
        font-size: 1.05rem;
        line-height: 1.7;
      }

      main {
        flex: 1;
        padding: 0 1.5rem 3rem;
        max-width: 1100px;
        width: 100%;
        margin: 0 auto 3rem;
      }

      .summary-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(240px, 1fr));
        gap: 1.5rem;
        margin-bottom: 2.5rem;
      }

      .metric-card {
        background: var(--card-bg);
        border-radius: 1.25rem;
        box-shadow: 0 24px 48px -32px var(--card-shadow);
        padding: 2rem;
        position: relative;
        overflow: hidden;
      }

      .metric-card::after {
        content: "";
        position: absolute;
        inset: 0;
        background: radial-gradient(circle at top right, var(--accent-soft), transparent 55%);
        pointer-events: none;
      }

      .metric-title {
        font-size: 0.95rem;
        font-weight: 600;
        text-transform: uppercase;
        color: var(--text-secondary);
        letter-spacing: 0.08em;
        margin-bottom: 0.75rem;
      }

      .metric-value {
        font-size: clamp(2.5rem, 5vw, 3.5rem);
        font-weight: 700;
        margin: 0;
      }

      .metric-delta {
        display: inline-flex;
        align-items: center;
        gap: 0.35rem;
        margin-top: 1rem;
        font-size: 0.95rem;
        border-radius: 999px;
        padding: 0.35rem 0.9rem;
        font-weight: 600;
      }

      .metric-delta.positive {
        background: rgba(5, 150, 105, 0.12);
        color: var(--success);
      }

      .metric-delta.negative {
        background: rgba(217, 119, 6, 0.12);
        color: var(--warning);
      }

      .metric-subtitle {
        margin-top: 1.2rem;
        color: var(--text-secondary);
        font-size: 0.95rem;
        display: flex;
        flex-direction: column;
        gap: 0.35rem;
      }

      .metric-footnote {
        font-size: 0.85rem;
      }

      section {
        margin-bottom: 2.5rem;
      }

      .section-heading {
        font-size: 1.4rem;
        margin-bottom: 0.5rem;
      }

      .section-subtitle {
        color: var(--text-secondary);
        margin-bottom: 1.5rem;
      }

      .table-wrapper {
        background: var(--card-bg);
        border-radius: 1rem;
        box-shadow: 0 18px 36px -28px var(--card-shadow);
        overflow: hidden;
      }

      table {
        width: 100%;
        border-collapse: collapse;
        min-width: 420px;
      }

      thead {
        background: rgba(37, 99, 235, 0.04);
      }

      th,
      td {
        padding: 1rem 1.25rem;
        text-align: left;
      }

      th {
        font-size: 0.85rem;
        text-transform: uppercase;
        color: var(--text-secondary);
        letter-spacing: 0.08em;
        font-weight: 600;
      }

      tbody tr {
        border-top: 1px solid rgba(15, 23, 42, 0.08);
      }

      tbody tr:nth-child(odd) {
        background: rgba(148, 163, 184, 0.08);
      }

      .muted {
        color: var(--text-secondary);
        font-size: 0.9rem;
      }

      .pill {
        display: inline-flex;
        padding: 0.25rem 0.65rem;
        border-radius: 999px;
        font-size: 0.75rem;
        font-weight: 600;
        background: rgba(15, 23, 42, 0.08);
        color: var(--text-secondary);
        font-variant-numeric: tabular-nums;
      }

      .case-pill {
        display: inline-flex;
        align-items: center;
        padding: 0.25rem 0.7rem;
        border-radius: 999px;
        font-size: 0.75rem;
        font-weight: 600;
        font-variant-numeric: tabular-nums;
      }

      .case-pill.success {
        background: rgba(5, 150, 105, 0.15);
        color: var(--success);
      }

      .case-pill.info {
        background: rgba(37, 99, 235, 0.15);
        color: var(--accent);
      }

      .case-pill.warning {
        background: rgba(217, 119, 6, 0.15);
        color: var(--warning);
      }

      .case-pill.secondary {
        background: rgba(148, 163, 184, 0.18);
        color: var(--text-secondary);
      }

      .case-pill + .case-pill {
        margin-top: 0.35rem;
      }

      .case-pill-wrapper {
        display: flex;
        flex-direction: column;
        gap: 0.35rem;
        align-items: flex-start;
      }

      .table-strong {
        font-weight: 600;
        font-size: 1rem;
        font-variant-numeric: tabular-nums;
        margin-bottom: 0.35rem;
      }

      .insight-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(260px, 1fr));
        gap: 1.5rem;
        margin-bottom: 2rem;
      }

      .bar-chart {
        display: flex;
        flex-direction: column;
        gap: 1.1rem;
        margin-top: 1.25rem;
      }

      .bar-row {
        display: flex;
        flex-direction: column;
        gap: 0.6rem;
      }

      .bar-row-header {
        display: flex;
        justify-content: space-between;
        align-items: baseline;
        gap: 1rem;
        font-size: 0.95rem;
        font-weight: 600;
      }

      .bar-label {
        flex: 1;
      }

      .bar-value {
        font-variant-numeric: tabular-nums;
        color: var(--text-secondary);
        font-size: 0.9rem;
        white-space: nowrap;
      }

      .bar-track {
        height: 0.6rem;
        border-radius: 999px;
        background: rgba(148, 163, 184, 0.25);
        overflow: hidden;
      }

      .bar-fill {
        height: 100%;
        border-radius: inherit;
        background: var(--accent);
        transition: width 0.4s ease;
      }

      .bar-fill.success {
        background: rgba(5, 150, 105, 0.75);
      }

      .bar-fill.info {
        background: rgba(37, 99, 235, 0.75);
      }

      .bar-fill.warning {
        background: rgba(217, 119, 6, 0.75);
      }

      .error-message {
        background: rgba(248, 113, 113, 0.2);
        color: #b91c1c;
        padding: 1rem 1.25rem;
        border-radius: 0.75rem;
        margin-top: 1.5rem;
      }

      footer {
        text-align: center;
        padding: 2rem 1.5rem 3rem;
        color: var(--text-secondary);
        font-size: 0.85rem;
      }

      @media (max-width: 640px) {
        header {
          padding: 2.5rem 1rem 1.5rem;
        }

        main {
          padding: 0 1rem 2.5rem;
        }

        .metric-card {
          padding: 1.75rem;
        }

        .bar-row-header {
          flex-direction: column;
          align-items: flex-start;
          gap: 0.35rem;
        }
      }
    </style>
  </head>
  <body>
    <header>
      <h1>Grading Accuracy Dashboard</h1>
      <p>
        Compare how closely the automated grading system and human reviewers align
        with the ground-truth labels. The metrics update automatically whenever
        the dataset is recomputed.
      </p>
    </header>

    <main>
      <section class="summary-grid" aria-live="polite">
        <article class="metric-card" id="autograder-card">
          <div class="metric-title">Autograder Accuracy</div>
          <p class="metric-value" id="autograder-accuracy">--</p>
          <div class="metric-subtitle">
            <span>Exact-match accuracy vs. ground truth</span>
            <span class="metric-footnote" id="autograder-sample">
              Based on -- automated evaluations.
            </span>
          </div>
        </article>

        <article class="metric-card" id="human-card">
          <div class="metric-title">Human Accuracy</div>
          <p class="metric-value" id="human-accuracy">--</p>
          <div class="metric-subtitle">
            <span>Exact-match accuracy vs. ground truth</span>
            <span class="metric-footnote" id="human-sample">
              Based on -- human reviews.
            </span>
          </div>
        </article>

        <article class="metric-card" id="dataset-card">
          <div class="metric-title">Evaluation Coverage</div>
          <p class="metric-value" id="total-evaluations">--</p>
          <div class="metric-subtitle">
            <span>Total human evaluations included in this refresh</span>
            <span class="metric-footnote" id="dataset-footnote">
              Across -- unique prompts.
            </span>
          </div>
        </article>
      </section>

      <section id="revision-section">
        <h2 class="section-heading">Revision insights</h2>
        <p class="section-subtitle">
          How often human reviewers revise the autograder and how those
          disagreements resolve against the ground truth.
        </p>

        <div class="insight-grid">
          <article class="metric-card" id="revision-overview-card">
            <div class="metric-title">Revision rate</div>
            <p class="metric-value" id="revision-rate">--</p>
            <div class="metric-subtitle">
              <span id="revision-volume">--</span>
              <span class="metric-footnote" id="revision-total">--</span>
            </div>
          </article>

          <article class="metric-card" id="revision-precision-card">
            <div class="metric-title">Correct revision precision</div>
            <p class="metric-value" id="revision-precision">--</p>
            <div class="metric-subtitle">
              <span id="revision-precision-detail">--</span>
              <span class="metric-footnote" id="revision-precision-footnote">--</span>
            </div>
          </article>

          <article class="metric-card" id="autograder-recall-card">
            <div class="metric-title">Autograder mistake recall</div>
            <p class="metric-value" id="autograder-recall">--</p>
            <div class="metric-subtitle">
              <span id="autograder-recall-detail">--</span>
              <span class="metric-footnote" id="autograder-recall-footnote">--</span>
            </div>
            <div
              id="autograder-recall-chart"
              class="bar-chart"
              role="list"
              aria-label="Autograder mistake breakdown"
            >
              <div class="muted">Awaiting data…</div>
            </div>
          </article>
        </div>

        <article class="metric-card" id="revision-case-card">
          <div class="metric-title">Revision outcomes</div>
          <div
            id="revision-case-chart"
            class="bar-chart"
            role="list"
            aria-label="Revision outcome breakdown"
          >
            <div class="muted">Awaiting data…</div>
          </div>
          <div class="metric-subtitle">
            <span>Share of revisions by outcome vs. ground truth</span>
          </div>
        </article>

        <div class="table-wrapper">
          <table>
            <thead>
              <tr>
                <th scope="col">Ground truth</th>
                <th scope="col">Revision rate</th>
                <th scope="col">Revisions</th>
                <th scope="col">Correct revision precision</th>
                <th scope="col">Autograder mistake recall</th>
                <th scope="col">Auto wrong → Human correct</th>
                <th scope="col">Auto correct → Human wrong</th>
                <th scope="col">Both wrong</th>
              </tr>
            </thead>
            <tbody id="revision-table-body">
              <tr>
                <td colspan="8" class="muted">Loading revision insights…</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div id="revision-empty" class="muted" hidden>
          No revision data available for this dataset.
        </div>
      </section>

      <section>
        <h2 class="section-heading">Prompt-level breakdown</h2>
        <p class="section-subtitle">
          Identify where the autograder excels or needs calibration compared with
          human reviewers.
        </p>
        <div class="table-wrapper">
          <table>
            <thead>
              <tr>
                <th scope="col">Prompt</th>
                <th scope="col">Responses</th>
                <th scope="col">Autograder</th>
                <th scope="col">Human</th>
                <th scope="col">Δ (Auto − Human)</th>
              </tr>
            </thead>
            <tbody id="prompt-table-body">
              <tr>
                <td colspan="5" class="muted">Loading metrics…</td>
              </tr>
            </tbody>
          </table>
        </div>
        <div id="prompt-empty" class="muted" hidden>
          No prompt-level breakdown is available for this dataset.
        </div>
        <div id="error" class="error-message" hidden></div>
      </section>
    </main>

    <footer>
      Accuracy is computed by the Python metrics pipeline. Refresh this page after
      regenerating <code>accuracy.json</code> to see the latest numbers.
    </footer>

    <script>
      const autograderAccuracyEl = document.getElementById("autograder-accuracy");
      const humanAccuracyEl = document.getElementById("human-accuracy");
      const totalEvaluationsEl = document.getElementById("total-evaluations");
      const autograderSampleEl = document.getElementById("autograder-sample");
      const humanSampleEl = document.getElementById("human-sample");
      const datasetFootnoteEl = document.getElementById("dataset-footnote");
      const promptTableBody = document.getElementById("prompt-table-body");
      const promptEmpty = document.getElementById("prompt-empty");
      const errorEl = document.getElementById("error");
      const revisionSection = document.getElementById("revision-section");
      const revisionRateEl = document.getElementById("revision-rate");
      const revisionVolumeEl = document.getElementById("revision-volume");
      const revisionTotalEl = document.getElementById("revision-total");
      const revisionPrecisionEl = document.getElementById("revision-precision");
      const revisionPrecisionDetailEl = document.getElementById(
        "revision-precision-detail"
      );
      const revisionPrecisionFootnoteEl = document.getElementById(
        "revision-precision-footnote"
      );
      const autograderRecallEl = document.getElementById("autograder-recall");
      const autograderRecallDetailEl = document.getElementById(
        "autograder-recall-detail"
      );
      const autograderRecallFootnoteEl = document.getElementById(
        "autograder-recall-footnote"
      );
      const autograderRecallChartEl = document.getElementById(
        "autograder-recall-chart"
      );
      const revisionCaseChartEl = document.getElementById("revision-case-chart");
      const revisionTableBody = document.getElementById("revision-table-body");
      const revisionEmpty = document.getElementById("revision-empty");

      const CASE_LABELS = {
        autograder_wrong_human_correct: "Autograder wrong → human corrected",
        autograder_correct_human_wrong: "Autograder correct → human wrong",
        both_wrong: "Both graders wrong",
      };

      const CASE_CLASS_MAP = {
        autograder_wrong_human_correct: "success",
        autograder_correct_human_wrong: "info",
        both_wrong: "warning",
      };

      const CASE_ORDER = [
        ["autograder_wrong_human_correct", "success"],
        ["autograder_correct_human_wrong", "info"],
        ["both_wrong", "warning"],
      ];

      const AUTOGRADER_BREAKDOWN_META = {
        corrected: {
          label: "Corrected by human revision",
          variant: "success",
        },
        not_revised: {
          label: "No revision applied",
          variant: "info",
        },
        revised_but_wrong: {
          label: "Revised but still wrong",
          variant: "warning",
        },
      };

      const AUTOGRADER_BREAKDOWN_ORDER = [
        "corrected",
        "not_revised",
        "revised_but_wrong",
      ];

      function formatPercent(value) {
        if (value === null || value === undefined) {
          return "--";
        }
        return `${(value * 100).toFixed(1)}%`;
      }

      function formatCount(count) {
        if (!Number.isFinite(count)) {
          return "--";
        }
        return count.toLocaleString();
      }

      function formatEvaluationSource(count, descriptor) {
        if (!Number.isFinite(count)) {
          return "Evaluation count unavailable.";
        }
        const [singular, plural] = Array.isArray(descriptor)
          ? descriptor
          : [descriptor, descriptor];
        const noun = count === 1 ? singular : plural;
        return `Based on ${formatCount(count)} ${noun}.`;
      }

      function formatPromptSummary(totalEvaluations, uniquePrompts) {
        if (!Number.isFinite(uniquePrompts) || uniquePrompts <= 0) {
          return "Unique prompt count unavailable.";
        }
        const promptLabel = uniquePrompts === 1 ? "unique prompt" : "unique prompts";
        const parts = [`Across ${formatCount(uniquePrompts)} ${promptLabel}`];
        if (Number.isFinite(totalEvaluations) && totalEvaluations > 0) {
          const average = totalEvaluations / uniquePrompts;
          if (Number.isFinite(average)) {
            parts.push(`≈${average.toFixed(1)} reviews per prompt`);
          }
        }
        return parts.join(" · ");
      }

      function formatLabel(label) {
        if (label === null || label === undefined) {
          return "—";
        }
        const text = String(label).trim();
        if (!text) {
          return "—";
        }
        if (/[A-Z]/.test(text)) {
          return text;
        }
        return text
          .split(/\s+/)
          .map((word) => word.charAt(0).toUpperCase() + word.slice(1))
          .join(" ");
      }

      function renderDelta(subject, comparison, subjectLabel, comparisonLabel) {
        const container = document.createElement("span");
        container.classList.add("metric-delta");
        const diff = subject - comparison;
        const formatted = `${diff > 0 ? "+" : ""}${(diff * 100).toFixed(1)}%`;
        container.textContent = `Δ vs. ${comparisonLabel}: ${formatted}`;
        container.title = `${subjectLabel} accuracy minus ${comparisonLabel.toLowerCase()} accuracy`;
        container.setAttribute(
          "aria-label",
          `${subjectLabel} accuracy compared with ${comparisonLabel.toLowerCase()} accuracy`
        );
        if (diff >= 0) {
          container.classList.add("positive");
        } else {
          container.classList.add("negative");
        }
        return container;
      }

      function updateCards(summary = {}) {
        autograderAccuracyEl.textContent = formatPercent(summary.autograder_accuracy);
        humanAccuracyEl.textContent = formatPercent(summary.human_accuracy);
        totalEvaluationsEl.textContent = formatCount(summary.total_evaluations);

        if (autograderSampleEl) {
          autograderSampleEl.textContent = formatEvaluationSource(
            summary.autograder_evaluations,
            ["automated prompt evaluation", "automated prompt evaluations"]
          );
        }

        if (humanSampleEl) {
          humanSampleEl.textContent = formatEvaluationSource(
            summary.human_evaluations,
            ["human review", "human reviews"]
          );
        }

        if (datasetFootnoteEl) {
          datasetFootnoteEl.textContent = formatPromptSummary(
            summary.total_evaluations,
            summary.unique_prompts
          );
        }

        const autograderCard = document.getElementById("autograder-card");
        const humanCard = document.getElementById("human-card");

        [autograderCard, humanCard].forEach((card) => {
          if (!card) {
            return;
          }
          const existingDelta = card.querySelector(".metric-delta");
          if (existingDelta) {
            existingDelta.remove();
          }
        });

        if (
          summary.autograder_accuracy !== null &&
          summary.autograder_accuracy !== undefined &&
          summary.human_accuracy !== null &&
          summary.human_accuracy !== undefined
        ) {
          humanCard.appendChild(
            renderDelta(
              summary.human_accuracy,
              summary.autograder_accuracy,
              "Human",
              "Autograder"
            )
          );
          autograderCard.appendChild(
            renderDelta(
              summary.autograder_accuracy,
              summary.human_accuracy,
              "Autograder",
              "Human"
            )
          );
        }
      }

      function renderRevisionCases(cases = {}, totalRevisions = 0) {
        if (!revisionCaseChartEl) {
          return;
        }
        revisionCaseChartEl.innerHTML = "";
        const hasRevisions = totalRevisions > 0;
        const entries = Object.keys(CASE_LABELS).map((key) => {
          const caseData = cases?.[key] || {};
          const count = Number.isFinite(caseData.count) ? caseData.count : 0;
          const shareValue = Number.isFinite(caseData.share_of_revisions)
            ? caseData.share_of_revisions
            : hasRevisions
            ? count / totalRevisions
            : 0;
          return {
            key,
            label: CASE_LABELS[key],
            count,
            share: Math.max(0, Math.min(shareValue, 1)),
          };
        });

        if (!hasRevisions) {
          const message = document.createElement("div");
          message.className = "muted";
          message.textContent = "No revisions recorded in this dataset.";
          revisionCaseChartEl.appendChild(message);
          return;
        }

        entries.forEach((entry) => {
          const row = document.createElement("div");
          row.className = "bar-row";
          row.setAttribute("role", "listitem");

          const header = document.createElement("div");
          header.className = "bar-row-header";

          const labelEl = document.createElement("span");
          labelEl.className = "bar-label";
          labelEl.textContent = entry.label;
          header.appendChild(labelEl);

          const percentText = `${(entry.share * 100).toFixed(1)}%`;
          const valueEl = document.createElement("span");
          valueEl.className = "bar-value";
          valueEl.textContent = `${formatCount(entry.count)} · ${percentText}`;
          header.appendChild(valueEl);

          row.appendChild(header);

          const track = document.createElement("div");
          track.className = "bar-track";

          const fill = document.createElement("div");
          fill.className = `bar-fill ${CASE_CLASS_MAP[entry.key] || ""}`.trim();
          fill.style.width = `${(entry.share * 100).toFixed(1)}%`;
          fill.setAttribute(
            "aria-label",
            `${entry.label}: ${percentText} of revisions`
          );
          track.appendChild(fill);

          row.appendChild(track);
          revisionCaseChartEl.appendChild(row);
        });
      }

      function renderAutograderRecallBreakdown(breakdown = {}, totalMistakes = 0) {
        if (!autograderRecallChartEl) {
          return;
        }
        autograderRecallChartEl.innerHTML = "";
        const hasMistakes = Number.isFinite(totalMistakes) && totalMistakes > 0;

        if (!hasMistakes) {
          const message = document.createElement("div");
          message.className = "muted";
          message.textContent = "No autograder mistakes recorded.";
          autograderRecallChartEl.appendChild(message);
          return;
        }

        AUTOGRADER_BREAKDOWN_ORDER.forEach((key) => {
          const entryMeta = AUTOGRADER_BREAKDOWN_META[key] || {
            label: key,
            variant: "",
          };
          const data = breakdown?.[key] || {};
          const count = Number.isFinite(data.count) ? data.count : 0;
          const shareValue = Number.isFinite(data.share_of_autograder_wrong)
            ? data.share_of_autograder_wrong
            : count / totalMistakes;
          const share = Math.max(0, Math.min(shareValue, 1));

          const row = document.createElement("div");
          row.className = "bar-row";
          row.setAttribute("role", "listitem");

          const header = document.createElement("div");
          header.className = "bar-row-header";

          const labelEl = document.createElement("span");
          labelEl.className = "bar-label";
          labelEl.textContent = entryMeta.label;
          header.appendChild(labelEl);

          const percentText = `${(share * 100).toFixed(1)}%`;
          const valueEl = document.createElement("span");
          valueEl.className = "bar-value";
          valueEl.textContent = `${formatCount(count)} · ${percentText}`;
          header.appendChild(valueEl);

          row.appendChild(header);

          const track = document.createElement("div");
          track.className = "bar-track";

          const fill = document.createElement("div");
          const variantClass = entryMeta.variant ? ` ${entryMeta.variant}` : "";
          fill.className = `bar-fill${variantClass}`;
          fill.style.width = `${(share * 100).toFixed(1)}%`;
          fill.setAttribute(
            "aria-label",
            `${entryMeta.label}: ${percentText} of autograder mistakes`
          );
          track.appendChild(fill);

          row.appendChild(track);
          autograderRecallChartEl.appendChild(row);
        });
      }

      function createCaseCell(entry, caseKey, variant) {
        const cell = document.createElement("td");
        const caseData = entry?.cases?.[caseKey] || {};
        const count = Number.isFinite(caseData.count) ? caseData.count : 0;
        const revisionCount = Number.isFinite(entry.revision_count)
          ? entry.revision_count
          : 0;
        const shareValue = Number.isFinite(caseData.share_of_revisions)
          ? caseData.share_of_revisions
          : revisionCount
          ? count / revisionCount
          : 0;
        const shareOfAutoWrong = Number.isFinite(
          caseData.share_of_autograder_wrong
        )
          ? caseData.share_of_autograder_wrong
          : null;

        const countEl = document.createElement("div");
        countEl.className = "table-strong";
        countEl.textContent = formatCount(count);
        cell.appendChild(countEl);

        const pillWrapper = document.createElement("div");
        pillWrapper.className = "case-pill-wrapper";

        const shareEl = document.createElement("span");
        shareEl.className = `case-pill ${variant}`.trim();
        shareEl.textContent = `${(shareValue * 100).toFixed(1)}% of revisions`;
        pillWrapper.appendChild(shareEl);

        if (shareOfAutoWrong !== null) {
          const recallPill = document.createElement("span");
          recallPill.className = "case-pill secondary";
          recallPill.textContent = `${(shareOfAutoWrong * 100).toFixed(
            1
          )}% of auto mistakes`;
          pillWrapper.appendChild(recallPill);
        }

        cell.appendChild(pillWrapper);

        return cell;
      }

      function updateRevisionTable(entries) {
        revisionTableBody.innerHTML = "";

        if (!entries || entries.length === 0) {
          revisionEmpty.hidden = false;
          const row = document.createElement("tr");
          const cell = document.createElement("td");
          cell.colSpan = 8;
          cell.className = "muted";
          cell.textContent = "No revision data available.";
          row.appendChild(cell);
          revisionTableBody.appendChild(row);
          return;
        }

        revisionEmpty.hidden = true;

        entries
          .slice()
          .sort((a, b) => (b.revision_rate ?? 0) - (a.revision_rate ?? 0))
          .forEach((entry) => {
            const row = document.createElement("tr");

            const labelCell = document.createElement("td");
            labelCell.textContent = formatLabel(
              entry.ground_truth_display || entry.ground_truth
            );
            row.appendChild(labelCell);

            const rateCell = document.createElement("td");
            rateCell.textContent = formatPercent(entry.revision_rate);
            row.appendChild(rateCell);

            const revisionsCell = document.createElement("td");
            const countEl = document.createElement("div");
            countEl.className = "table-strong";
            countEl.textContent = formatCount(entry.revision_count);
            revisionsCell.appendChild(countEl);
            const subtitle = document.createElement("div");
            subtitle.className = "muted";
            subtitle.textContent = `${formatCount(entry.total_evaluations)} evaluations`;
            revisionsCell.appendChild(subtitle);
            row.appendChild(revisionsCell);

            const precisionCell = document.createElement("td");
            const precisionValue = document.createElement("div");
            precisionValue.className = "table-strong";
            precisionValue.textContent = formatPercent(
              entry.correct_revision_precision
            );
            precisionCell.appendChild(precisionValue);
            const precisionDetail = document.createElement("div");
            precisionDetail.className = "muted";
            const correctRevisionCount = Number.isFinite(entry.correct_revision_count)
              ? entry.correct_revision_count
              : 0;
            const revisionCount = Number.isFinite(entry.revision_count)
              ? entry.revision_count
              : 0;
            if (revisionCount) {
              precisionDetail.textContent = `${formatCount(
                correctRevisionCount
              )} of ${formatCount(revisionCount)} revisions`;
            } else {
              precisionDetail.textContent = `${formatCount(
                correctRevisionCount
              )} correct revisions`;
            }
            precisionCell.appendChild(precisionDetail);
            row.appendChild(precisionCell);

            const recallCell = document.createElement("td");
            const recallValue = document.createElement("div");
            recallValue.className = "table-strong";
            recallValue.textContent = formatPercent(entry.autograder_wrong_recall);
            recallCell.appendChild(recallValue);
            const recallDetail = document.createElement("div");
            recallDetail.className = "muted";
            const correctedMistakes = Number.isFinite(
              entry.corrected_autograder_wrong
            )
              ? entry.corrected_autograder_wrong
              : 0;
            const totalMistakes = Number.isFinite(entry.autograder_wrong_total)
              ? entry.autograder_wrong_total
              : 0;
            if (totalMistakes) {
              recallDetail.textContent = `${formatCount(
                correctedMistakes
              )} of ${formatCount(totalMistakes)} mistakes`;
            } else {
              recallDetail.textContent = `${formatCount(
                correctedMistakes
              )} mistakes corrected`;
            }
            recallCell.appendChild(recallDetail);
            row.appendChild(recallCell);

            CASE_ORDER.forEach(([caseKey, variant]) => {
              row.appendChild(createCaseCell(entry, caseKey, variant));
            });

            revisionTableBody.appendChild(row);
          });
      }

      function updateRevisionInsights(revision) {
        if (!revisionSection) {
          return;
        }

        if (!revision) {
          revisionSection.hidden = true;
          return;
        }

        revisionSection.hidden = false;

        const overall = revision.overall || {};
        const revisionCount = Number.isFinite(overall.revision_count)
          ? overall.revision_count
          : 0;
        const totalEvaluations = Number.isFinite(overall.total_evaluations)
          ? overall.total_evaluations
          : null;
        const correctRevisionCount = Number.isFinite(overall.correct_revision_count)
          ? overall.correct_revision_count
          : 0;
        const autograderMistakeTotal = Number.isFinite(
          overall.autograder_wrong_total
        )
          ? overall.autograder_wrong_total
          : 0;
        const correctedMistakes = Number.isFinite(
          overall.corrected_autograder_wrong
        )
          ? overall.corrected_autograder_wrong
          : 0;

        revisionRateEl.textContent = formatPercent(overall.revision_rate);
        revisionVolumeEl.textContent = `${formatCount(revisionCount)} revisions`;
        if (totalEvaluations !== null) {
          const noun = totalEvaluations === 1 ? "human review" : "human reviews";
          revisionTotalEl.textContent = `Out of ${formatCount(totalEvaluations)} ${noun}`;
        } else {
          revisionTotalEl.textContent = "Total human reviews unavailable.";
        }

        if (revisionPrecisionEl) {
          revisionPrecisionEl.textContent = formatPercent(
            overall.correct_revision_precision
          );
        }
        if (revisionPrecisionDetailEl) {
          revisionPrecisionDetailEl.textContent = `${formatCount(
            correctRevisionCount
          )} correct revisions`;
        }
        if (revisionPrecisionFootnoteEl) {
          if (revisionCount) {
            revisionPrecisionFootnoteEl.textContent = `Out of ${formatCount(
              revisionCount
            )} total revisions.`;
          } else {
            revisionPrecisionFootnoteEl.textContent = "No revisions recorded.";
          }
        }

        if (autograderRecallEl) {
          autograderRecallEl.textContent = formatPercent(
            overall.autograder_wrong_recall
          );
        }
        if (autograderRecallDetailEl) {
          autograderRecallDetailEl.textContent = `${formatCount(
            correctedMistakes
          )} mistakes corrected`;
        }
        if (autograderRecallFootnoteEl) {
          if (autograderMistakeTotal) {
            const noun =
              autograderMistakeTotal === 1
                ? "autograder mistake"
                : "autograder mistakes";
            autograderRecallFootnoteEl.textContent = `Out of ${formatCount(
              autograderMistakeTotal
            )} ${noun}.`;
          } else {
            autograderRecallFootnoteEl.textContent =
              "No autograder mistakes detected.";
          }
        }

        renderRevisionCases(revision.cases, revisionCount);
        renderAutograderRecallBreakdown(
          revision.autograder_wrong_breakdown,
          autograderMistakeTotal
        );
        updateRevisionTable(revision.by_ground_truth || []);
      }

      function updatePromptTable(entries) {
        promptTableBody.innerHTML = "";

        if (!entries || entries.length === 0) {
          promptEmpty.hidden = false;
          const row = document.createElement("tr");
          const cell = document.createElement("td");
          cell.colSpan = 5;
          cell.className = "muted";
          cell.textContent = "No prompt data";
          row.appendChild(cell);
          promptTableBody.appendChild(row);
          return;
        }

        promptEmpty.hidden = true;

        entries
          .slice()
          .sort((a, b) => a.prompt_id.localeCompare(b.prompt_id))
          .forEach((entry) => {
            const row = document.createElement("tr");

            const promptCell = document.createElement("td");
            promptCell.textContent = entry.prompt_id;
            row.appendChild(promptCell);

            const countCell = document.createElement("td");
            countCell.textContent = formatCount(entry.count);
            row.appendChild(countCell);

            const autoCell = document.createElement("td");
            autoCell.textContent = formatPercent(entry.autograder_accuracy);
            row.appendChild(autoCell);

            const humanCell = document.createElement("td");
            humanCell.textContent = formatPercent(entry.human_accuracy);
            row.appendChild(humanCell);

            const deltaCell = document.createElement("td");
            if (
              entry.autograder_accuracy !== null &&
              entry.autograder_accuracy !== undefined &&
              entry.human_accuracy !== null &&
              entry.human_accuracy !== undefined
            ) {
              const diff = entry.autograder_accuracy - entry.human_accuracy;
              const badge = document.createElement("span");
              badge.classList.add("pill");
              badge.textContent = `${diff > 0 ? "+" : ""}${(diff * 100).toFixed(1)}%`;
              badge.title = "Autograder accuracy minus human accuracy";
              badge.setAttribute(
                "aria-label",
                `Autograder minus human accuracy: ${(diff * 100).toFixed(1)}%`
              );
              deltaCell.appendChild(badge);
            } else {
              deltaCell.textContent = "--";
            }
            row.appendChild(deltaCell);

            promptTableBody.appendChild(row);
          });
      }

      async function fetchJson(path) {
        const response = await fetch(path, { cache: "no-store" });
        if (!response.ok) {
          throw new Error(`Failed to load ${path} (${response.status})`);
        }
        return response.json();
      }

      async function loadMetrics() {
        try {
          const data = await fetchJson("accuracy.json");
          updateCards(data.summary || {});
          updatePromptTable(data.per_prompt || []);
          if (errorEl) {
            errorEl.hidden = true;
            errorEl.textContent = "";
          }
        } catch (error) {
          console.error(error);
          if (errorEl) {
            errorEl.hidden = false;
            errorEl.textContent =
              "We were unable to load the latest accuracy metrics. Confirm that accuracy.json has been generated.";
          }
          promptTableBody.innerHTML = "";
          updateRevisionInsights(null);
          return;
        }

        try {
          const revisionData = await fetchJson("revision.json");
          updateRevisionInsights(revisionData);
        } catch (error) {
          console.error(error);
          updateRevisionInsights(null);
        }
      }

      loadMetrics();
    </script>
  </body>
</html>
